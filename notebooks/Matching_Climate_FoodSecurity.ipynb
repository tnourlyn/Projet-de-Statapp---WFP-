{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2eb99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DIAGNOSTIC DE CORRESPONDANCE DES NOMS  ---\n",
      "Fichier Climat chargÃ© (43620 lignes)\n",
      "Fichier IPC chargÃ© (12185 lignes)\n",
      "\n",
      "--- RÃ‰SULTAT DU MATCHING ---\n",
      "RÃ©gions uniques Climat (GADM) : 724\n",
      "RÃ©gions uniques IPC (WFP)     : 568\n",
      "------------------------------\n",
      "MATCH PARFAIT : 429 rÃ©gions\n",
      "PROBLÃˆMES     : 434 rÃ©gions ne correspondent pas\n",
      " Taux de couverture IPC : 75.5%\n",
      "\n",
      "Exemples de rÃ©gions IPC introuvables cÃ´tÃ© Climat (Ã  renommer) :\n",
      "['BIRNIN-GWARI', 'OGU/BOLO', 'REMO NORTH', 'YAGBA WEST', 'ABA NORTH', 'MUBI NORTH', 'OWAN WEST', 'KOSOFE', 'BARIKIN LADI', 'ENUGU EAST']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"--- DIAGNOSTIC DE CORRESPONDANCE DES NOMS  ---\")\n",
    "\n",
    "# 1. Charger  fichier CLIMAT (GADM)\n",
    "# Assure-toi que ce fichier est bien crÃ©Ã© par ton Ã©tape prÃ©cÃ©dente\n",
    "file_climate = \"FLDAS_Nigeria_Admin2_Aggregated.csv\"\n",
    "\n",
    "try:\n",
    "    df_clim = pd.read_csv(file_climate)\n",
    "    print(f\"Fichier Climat chargÃ© ({len(df_clim)} lignes)\")\n",
    "    \n",
    "    # 2. Charger  fichier IPC (CIBLE)\n",
    "    \n",
    "    file_ipc = \"IPC.xlsx\" \n",
    "    \n",
    "    \n",
    "   \n",
    "    try:\n",
    "        df_ipc = pd.read_excel(file_ipc) \n",
    "        print(f\"Fichier IPC chargÃ© ({len(df_ipc)} lignes)\")\n",
    "\n",
    "        # --- PARAMÃˆTRES ---\n",
    "        col_ipc_name = 'adm2_name'   # LE VRAI NOM (TrouvÃ© grÃ¢ce Ã  ton fichier)\n",
    "        col_clim_name = 'NAME_2'     # Standard GADM\n",
    "        \n",
    "        # 3. La Comparaison\n",
    "        # On met tout en MAJUSCULES et on enlÃ¨ve les espaces vides autour (.strip())\n",
    "        set_clim = set(df_clim[col_clim_name].astype(str).str.upper().str.strip())\n",
    "        set_ipc = set(df_ipc[col_ipc_name].astype(str).str.upper().str.strip())\n",
    "\n",
    "        match = set_clim.intersection(set_ipc)\n",
    "        only_clim = set_clim - set_ipc # Ce qu'on a en mÃ©tÃ©o mais pas en IPC\n",
    "        only_ipc = set_ipc - set_clim  # Ce qu'on a en IPC mais pas en mÃ©tÃ©o\n",
    "\n",
    "        print(f\"\\n--- RÃ‰SULTAT DU MATCHING ---\")\n",
    "        print(f\"RÃ©gions uniques Climat (GADM) : {len(set_clim)}\")\n",
    "        print(f\"RÃ©gions uniques IPC (WFP)     : {len(set_ipc)}\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"MATCH PARFAIT : {len(match)} rÃ©gions\")\n",
    "        print(f\"PROBLÃˆMES     : {len(only_clim) + len(only_ipc)} rÃ©gions ne correspondent pas\")\n",
    "        \n",
    "        # Calcul du score\n",
    "        score = len(match) / len(set_ipc) * 100\n",
    "        print(f\" Taux de couverture IPC : {score:.1f}%\")\n",
    "\n",
    "        if len(only_ipc) > 0:\n",
    "            print(\"\\nExemples de rÃ©gions IPC introuvables cÃ´tÃ© Climat (Ã  renommer) :\")\n",
    "            print(list(only_ipc)[:10])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture IPC : {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lecture Climat : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9209cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur : 'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "# 1. Chargement des fichiers\n",
    "# Adapter les noms de fichiers si nÃ©cessaire\n",
    "file_climate = \"FLDAS_Nigeria_Admin2_Aggregated.csv\"\n",
    "file_ipc = \"IPC.xlsx\" \n",
    "\n",
    "try:\n",
    "    df_clim = pd.read_csv(file_climate)\n",
    "    df_ipc = pd.read_csv(file_ipc) \n",
    "\n",
    "    # 2. Extraction des listes de rÃ©gions\n",
    "    # Nettoyage des noms (majuscules + suppression espaces) pour comparer\n",
    "    gadm_names = sorted(list(set(df_clim['NAME_2'].astype(str).str.upper().str.strip())))\n",
    "    ipc_names = sorted(list(set(df_ipc['adm2_name'].astype(str).str.upper().str.strip())))\n",
    "\n",
    "    # 3. Identification des orphelins (Ceux qui sont dans IPC mais pas dans GADM)\n",
    "    only_ipc = [name for name in ipc_names if name not in gadm_names]\n",
    "\n",
    "    print(f\"Recherche de correspondances pour {len(only_ipc)} rÃ©gions...\")\n",
    "\n",
    "    # 4. Algorithme de correspondance (Fuzzy Matching)\n",
    "    print(\"\\n--- Dictionnaire de correction suggÃ©rÃ© ---\")\n",
    "    print(\"correction_dict = {\")\n",
    "    \n",
    "    for name in only_ipc:\n",
    "        # On cherche le nom le plus proche dans la liste GADM\n",
    "        # cutoff=0.6 signifie qu'il faut au moins 60% de ressemblance\n",
    "        matches = difflib.get_close_matches(name, gadm_names, n=1, cutoff=0.6)\n",
    "        \n",
    "        if matches:\n",
    "            print(f'    \"{name}\": \"{matches[0]}\",')\n",
    "        else:\n",
    "            # Si aucune ressemblance trouvÃ©e\n",
    "            print(f'    # \"{name}\": \"???\", # Aucune correspondance trouvÃ©e')\n",
    "            \n",
    "    print(\"}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c15fb172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chargement du fichier Excel : IPC.xlsx ---\n",
      "âœ… Climat chargÃ© : 43620 lignes.\n",
      "âœ… IPC chargÃ© : 12185 lignes.\n",
      "\n",
      "--- DICTIONNAIRE DE CORRECTION (139 rÃ©gions Ã  mapper) ---\n",
      "correction_dict = {\n",
      "    \"ABA NORTH\": \"AWKANORTH\",\n",
      "    \"ABA SOUTH\": \"ABASOUTH\",\n",
      "    \"ABEOKUTA NORTH\": \"ABEOKUTANORTH\",\n",
      "    \"ABEOKUTA SOUTH\": \"ABEOKUTASOUTH\",\n",
      "    \"ADO EKITI\": \"ADO-EKITI\",\n",
      "    \"ADO-ODO/OTA\": \"ADOODO/OTA\",\n",
      "    \"AGEGE\": \"NANGERE\",\n",
      "    \"AHOADA EAST\": \"AHOADAEAST\",\n",
      "    \"AHOADA WEST\": \"AHOADAWEST\",\n",
      "    \"AJEROMI-IFELODUN\": \"IFELODUN\",\n",
      "    \"AKUKU TORU\": \"AKUKU-TORU\",\n",
      "    \"AMUWO-ODOFIN\": \"AMUWOODOFIN\",\n",
      "    \"AREWA-DANDI\": \"AREWADANDI\",\n",
      "    \"BAKASSI\": \"TAKAI\",\n",
      "    \"BARIKIN LADI\": \"BARKINLADI\",\n",
      "    \"BEKWARA\": \"BEKWARRA\",\n",
      "    \"BENUE\": \"BENDE\",\n",
      "    \"BIDA\": \"BINDAWA\",\n",
      "    \"BIRNI KUDU\": \"BIRNINKUDU\",\n",
      "    \"BIRNIN KEBBI\": \"BIRNINKEBBI\",\n",
      "    \"BIRNIN MAGAJI\": \"BIRNINGWARI\",\n",
      "    \"BIRNIN-GWARI\": \"BIRNINGWARI\",\n",
      "    \"BURSARI\": \"BORSARI\",\n",
      "    \"BURUKU\": \"BURUTU\",\n",
      "    \"CALABAR SOUTH\": \"CALABARSOUTH\",\n",
      "    \"CHANCHAGA\": \"SHANGA\",\n",
      "    \"DALA\": \"YALA\",\n",
      "    \"DAN MUSA\": \"DANMUSA\",\n",
      "    \"DAWAKIN KUDU\": \"DAWAKINKUDU\",\n",
      "    \"DAWAKIN TOFA\": \"DAWAKINTOFA\",\n",
      "    \"DUTSIN-MA\": \"DUTSINMA\",\n",
      "    \"EKITI EAST\": \"EKITIEAST\",\n",
      "    \"EKITI SOUTH WEST\": \"EKITISOUTH-WEST\",\n",
      "    \"EKITI WEST\": \"EKITIWEST\",\n",
      "    \"EMOHUA\": \"EMUOHA\",\n",
      "    \"EMURE\": \"LERE\",\n",
      "    \"ENUGU EAST\": \"ENUGUEAST\",\n",
      "    \"ENUGU NORTH\": \"ENUGUNORTH\",\n",
      "    \"ENUGU SOUTH\": \"ENUGUNORTH\",\n",
      "    \"ESAN CENTRAL\": \"ESANCENTRAL\",\n",
      "    \"ESAN NORTH EAST\": \"ESANNORTH-EAST\",\n",
      "    \"ESAN SOUTH EAST\": \"ESANSOUTH-EAST\",\n",
      "    \"ESAN SOUTH WEST\": \"ESANSOUTH-EAST\",\n",
      "    \"ESAN WEST\": \"ESANWEST\",\n",
      "    \"ETSAKO CENTRAL\": \"ETSAKOCENTRAL\",\n",
      "    \"ETSAKO EAST\": \"ETSAKOEAST\",\n",
      "    \"ETSAKO WEST\": \"ETSAKOWEST\",\n",
      "    \"FAGGE\": \"AUGIE\",\n",
      "    \"GARUM MALLAM\": \"GARUMMALLAM\",\n",
      "    \"GIREI\": \"GIRIE\",\n",
      "    \"GOMBE\": \"GOMBI\",\n",
      "    \"GWALE\": \"WASE\",\n",
      "    \"GWER EAST\": \"GWEREAST\",\n",
      "    \"GWER WEST\": \"GWERWEST\",\n",
      "    \"IBEJU/LEKKI\": \"IBEJU-LEKKI\",\n",
      "    \"IDAH\": \"IDANRE\",\n",
      "    \"IFAKO-IJAYE\": \"FUNAKAYE\",\n",
      "    \"IGBO-EZE NORTH\": \"IGBO-EZENORTH\",\n",
      "    \"IGBO-EZE SOUTH\": \"IGBO-EZESOUTH\",\n",
      "    \"IJEBU EAST\": \"IJEBUEAST\",\n",
      "    \"IJEBU NORTH\": \"IJEBUNORTH\",\n",
      "    \"IJEBU NORTH EAST\": \"IJEBUNORTH-EAST\",\n",
      "    \"IJEBU ODE\": \"IJEBU-ODE\",\n",
      "    \"ILEJEMEJI\": \"ILEJEMEJE\",\n",
      "    \"ILORIN EAST\": \"ILORINEAST\",\n",
      "    \"ILORIN SOUTH\": \"ILORINSOUTH\",\n",
      "    \"ILORIN WEST\": \"ILORINWEST\",\n",
      "    \"ISIALANGWA NORTH\": \"ISIALANGWANORTH\",\n",
      "    \"ISIALANGWA SOUTH\": \"ISIALANGWASOUTH\",\n",
      "    \"JOS EAST\": \"JOSEAST\",\n",
      "    \"JOS NORTH\": \"JOSNORTH\",\n",
      "    \"JOS SOUTH\": \"JOSSOUTH\",\n",
      "    \"KADUNA NORTH\": \"KADUNANORTH\",\n",
      "    \"KADUNA SOUTH\": \"KADUNANORTH\",\n",
      "    \"KAFIN HAUSA\": \"KAFINHAUSA\",\n",
      "    \"KARIM-LAMIDO\": \"KARIMLAMIDO\",\n",
      "    \"KAURA NAMODA\": \"KAURANAMODA\",\n",
      "    \"KIRI KASAMMA\": \"KIRIKASAMA\",\n",
      "    \"KOSOFE\": \"OSE\",\n",
      "    \"KUMBOTSO\": \"BOSSO\",\n",
      "    \"KWAYA KUSAR\": \"KWAYAKUSAR\",\n",
      "    \"LAGOS ISLAND\": \"LAGOSISLAND\",\n",
      "    \"LAGOS MAINLAND\": \"LAGOSISLAND\",\n",
      "    \"LANGTANG NORTH\": \"LANGTANGNORTH\",\n",
      "    \"LANGTANG SOUTH\": \"LANGTANGSOUTH\",\n",
      "    \"MAIDUGURI\": \"MAGUMERI\",\n",
      "    \"MALAM MADORI\": \"MALAMMADURI\",\n",
      "    \"MARKAFI\": \"MAKARFI\",\n",
      "    \"MUBI NORTH\": \"MUBINORTH\",\n",
      "    \"MUBI SOUTH\": \"MUBISOUTH\",\n",
      "    \"NAN\": \"NUMAN\",\n",
      "    \"NASARAWA-EGGON\": \"NASARAWAEGGON\",\n",
      "    \"NKANU EAST\": \"NKANUEAST\",\n",
      "    \"NKANU WEST\": \"NKANUWEST\",\n",
      "    \"OBIA/AKPOR\": \"OBIO/AKPOR\",\n",
      "    \"OFFA\": \"TOFA\",\n",
      "    \"OGU/BOLO\": \"ODOGBOLU\",\n",
      "    \"OGUN WATERSIDE\": \"OGUNWATERSIDE\",\n",
      "    \"OLAMABOLO\": \"OLAMABORO\",\n",
      "    \"OPOBO/NKORO\": \"OBIO/AKPOR\",\n",
      "    \"OSISIOMA\": \"OSISIOMANGWA\",\n",
      "    \"OTURKPO\": \"OTUKPO\",\n",
      "    \"OVIA NORTH EAST\": \"OVIANORTH-EAST\",\n",
      "    \"OVIA SOUTH WEST\": \"OVIASOUTH-WEST\",\n",
      "    \"OWAN EAST\": \"OWANEAST\",\n",
      "    \"OWAN WEST\": \"OWANWEST\",\n",
      "    \"PORT-HARCOURT\": \"PORTHARCOURT\",\n",
      "    \"QUA'AN PAN\": \"QUA'ANPAN\",\n",
      "    \"REMO NORTH\": \"REMO-NORTH\",\n",
      "    \"RIMIN GADO\": \"RIMINGADO\",\n",
      "    \"SABON BIRNI\": \"SABONBIRNI\",\n",
      "    \"SABON-GARI\": \"SABONGARI\",\n",
      "    \"SHOMOLU\": \"SHOMGOM\",\n",
      "    \"SOKOTO NORTH\": \"SOKOTONORTH\",\n",
      "    \"SOKOTO SOUTH\": \"ISOKOSOUTH\",\n",
      "    \"SULE-TANKARKAR\": \"SULETANKARKAR\",\n",
      "    \"TALATA MAFARA\": \"TALATA-MAFARA\",\n",
      "    \"TARMUA\": \"TARMUWA\",\n",
      "    \"TOUNGO\": \"TEUNGO\",\n",
      "    \"TUDUN WADA\": \"TUDUNWADA\",\n",
      "    \"UKWA EAST\": \"UKWAEAST\",\n",
      "    \"UKWA WEST\": \"UKWAWEST\",\n",
      "    \"UMUAHIA NORTH\": \"UMUAHIANORTH\",\n",
      "    \"UMUAHIA SOUTH\": \"UMUAHIASOUTH\",\n",
      "    \"UMUNNEOCHE\": \"UMUNNEOCHI\",\n",
      "    \"YAGBA EAST\": \"YAGBAEAST\",\n",
      "    \"YAGBA WEST\": \"YAGBAWEST\",\n",
      "    \"YEWA NORTH\": \"YEWANORTH\",\n",
      "    \"YEWA SOUTH\": \"YEWASOUTH\",\n",
      "    \"YOLA NORTH\": \"YOLANORTH\",\n",
      "    \"YOLA SOUTH\": \"YOLASOUTH\",\n",
      "    \"ZANGO-KATAF\": \"ZANGONKATAF\",\n",
      "}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "# Configuration\n",
    "file_climate = \"FLDAS_Nigeria_Admin2_Aggregated.csv\"\n",
    "file_ipc = \"IPC.xlsx\" # Assure-toi que c'est le bon nom (avec .xlsx)\n",
    "\n",
    "print(f\"--- Chargement du fichier Excel : {file_ipc} ---\")\n",
    "\n",
    "# 1. Chargement du fichier Climat\n",
    "try:\n",
    "    df_clim = pd.read_csv(file_climate)\n",
    "    print(f\"âœ… Climat chargÃ© : {len(df_clim)} lignes.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur Climat : {e}\")\n",
    "    df_clim = None\n",
    "\n",
    "# 2. Chargement du fichier IPC (VERSION EXCEL)\n",
    "try:\n",
    "    # âš ï¸ C'est ici que Ã§a change : on utilise read_excel !\n",
    "    df_ipc = pd.read_excel(file_ipc)\n",
    "    print(f\"âœ… IPC chargÃ© : {len(df_ipc)} lignes.\")\n",
    "    \n",
    "    # Nettoyage des noms de colonnes\n",
    "    df_ipc.columns = df_ipc.columns.str.strip()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur IPC : {e}\")\n",
    "    print(\"VÃ©rifie que le fichier s'appelle bien 'IPC.xlsx' et qu'il n'est pas ouvert dans Excel.\")\n",
    "    df_ipc = None\n",
    "\n",
    "# 3. CrÃ©ation du Dictionnaire\n",
    "if df_clim is not None and df_ipc is not None:\n",
    "    # On cherche la colonne Admin2\n",
    "    col_ipc = 'adm2_name'\n",
    "    if col_ipc not in df_ipc.columns:\n",
    "        print(f\"âš ï¸ Colonne '{col_ipc}' introuvable. Colonnes dispo : {list(df_ipc.columns)}\")\n",
    "        # Essaye de trouver une colonne qui ressemble\n",
    "        candidats = [c for c in df_ipc.columns if \"adm2\" in c.lower() or \"area\" in c.lower()]\n",
    "        if candidats:\n",
    "            col_ipc = candidats[0]\n",
    "            print(f\"ðŸ‘‰ Utilisation de la colonne : {col_ipc}\")\n",
    "\n",
    "    if col_ipc in df_ipc.columns:\n",
    "        gadm_names = sorted(list(set(df_clim['NAME_2'].astype(str).str.upper().str.strip())))\n",
    "        ipc_names = sorted(list(set(df_ipc[col_ipc].astype(str).str.upper().str.strip())))\n",
    "\n",
    "        only_ipc = [n for n in ipc_names if n not in gadm_names]\n",
    "\n",
    "        print(f\"\\n--- DICTIONNAIRE DE CORRECTION ({len(only_ipc)} rÃ©gions Ã  mapper) ---\")\n",
    "        print(\"correction_dict = {\")\n",
    "        \n",
    "        for name in only_ipc:\n",
    "            matches = difflib.get_close_matches(name, gadm_names, n=1, cutoff=0.6)\n",
    "            if matches:\n",
    "                print(f'    \"{name}\": \"{matches[0]}\",')\n",
    "            else:\n",
    "                pass \n",
    "                \n",
    "        print(\"}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bae43d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion en cours...\n",
      "SUCCÃˆS ! Dataset final crÃ©Ã© : 579960 lignes !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Chargement\n",
    "file_climate = \"FLDAS_Nigeria_Admin2_Aggregated.csv\"\n",
    "file_ipc = \"IPC.xlsx\"\n",
    "\n",
    "df_clim = pd.read_csv(file_climate)\n",
    "df_ipc = pd.read_excel(file_ipc)\n",
    "\n",
    "# =================================================================\n",
    "# ðŸ‘‡ C'EST ICI QUE Ã‡A MANQUAIT ! ON MET LE CLIMAT EN MAJUSCULES ðŸ‘‡\n",
    "df_clim['NAME_2'] = df_clim['NAME_2'].astype(str).str.upper().str.strip()\n",
    "# =================================================================\n",
    "\n",
    "# 2. Nettoyage IPC (Comme avant)\n",
    "df_ipc.columns = df_ipc.columns.str.strip()\n",
    "\n",
    "# Ton dictionnaire nettoyÃ© (celui oÃ¹ tu as enlevÃ© les bÃªtises)\n",
    "correction_dict = {\n",
    "    \"ABA NORTH\": \"AWKANORTH\",\n",
    "    \"ABA SOUTH\": \"ABASOUTH\",\n",
    "    \"ABEOKUTA NORTH\": \"ABEOKUTANORTH\",\n",
    "    \"ABEOKUTA SOUTH\": \"ABEOKUTASOUTH\",\n",
    "    \"ADO EKITI\": \"ADO-EKITI\",\n",
    "    \"ADO-ODO/OTA\": \"ADOODO/OTA\",\n",
    "    \"AHOADA EAST\": \"AHOADAEAST\",\n",
    "    \"AHOADA WEST\": \"AHOADAWEST\",\n",
    "    \"AJEROMI-IFELODUN\": \"IFELODUN\",\n",
    "    \"AKUKU TORU\": \"AKUKU-TORU\",\n",
    "    \"AMUWO-ODOFIN\": \"AMUWOODOFIN\",\n",
    "    \"AREWA-DANDI\": \"AREWADANDI\",\n",
    "    \"BARIKIN LADI\": \"BARKINLADI\",\n",
    "    \"BIRNIN KEBBI\": \"BIRNINKEBBI\",\n",
    "    \"BIRNIN-GWARI\": \"BIRNINGWARI\",\n",
    "    \"CALABAR SOUTH\": \"CALABARSOUTH\",\n",
    "    \"DAWAKIN KUDU\": \"DAWAKINKUDU\",\n",
    "    \"DAWAKIN TOFA\": \"DAWAKINTOFA\",\n",
    "    \"DUTSIN-MA\": \"DUTSINMA\",\n",
    "    \"EKITI EAST\": \"EKITIEAST\",\n",
    "    \"EKITI SOUTH WEST\": \"EKITISOUTH-WEST\",\n",
    "    \"EKITI WEST\": \"EKITIWEST\",\n",
    "    \"ENUGU EAST\": \"ENUGUEAST\",\n",
    "    \"ENUGU NORTH\": \"ENUGUNORTH\",\n",
    "    \"ESAN CENTRAL\": \"ESANCENTRAL\",\n",
    "    \"ESAN NORTH EAST\": \"ESANNORTH-EAST\",\n",
    "    \"ESAN SOUTH EAST\": \"ESANSOUTH-EAST\",\n",
    "    \"ESAN WEST\": \"ESANWEST\",\n",
    "    \"ETSAKO CENTRAL\": \"ETSAKOCENTRAL\",\n",
    "    \"ETSAKO EAST\": \"ETSAKOEAST\",\n",
    "    \"ETSAKO WEST\": \"ETSAKOWEST\",\n",
    "    \"GWER EAST\": \"GWEREAST\",\n",
    "    \"GWER WEST\": \"GWERWEST\",\n",
    "    \"IBEJU/LEKKI\": \"IBEJU-LEKKI\",\n",
    "    \"IGBO-EZE NORTH\": \"IGBO-EZENORTH\",\n",
    "    \"IGBO-EZE SOUTH\": \"IGBO-EZESOUTH\",\n",
    "    \"IJEBU EAST\": \"IJEBUEAST\",\n",
    "    \"IJEBU NORTH\": \"IJEBUNORTH\",\n",
    "    \"IJEBU NORTH EAST\": \"IJEBUNORTH-EAST\",\n",
    "    \"IJEBU ODE\": \"IJEBU-ODE\",\n",
    "    \"ILORIN EAST\": \"ILORINEAST\",\n",
    "    \"ILORIN SOUTH\": \"ILORINSOUTH\",\n",
    "    \"ILORIN WEST\": \"ILORINWEST\",\n",
    "    \"ISIALANGWA NORTH\": \"ISIALANGWANORTH\",\n",
    "    \"ISIALANGWA SOUTH\": \"ISIALANGWASOUTH\",\n",
    "    \"JOS EAST\": \"JOSEAST\",\n",
    "    \"JOS NORTH\": \"JOSNORTH\",\n",
    "    \"JOS SOUTH\": \"JOSSOUTH\",\n",
    "    \"KADUNA NORTH\": \"KADUNANORTH\",\n",
    "    \"KARIM-LAMIDO\": \"KARIMLAMIDO\",\n",
    "    \"KAURA NAMODA\": \"KAURANAMODA\",\n",
    "    \"LAGOS ISLAND\": \"LAGOSISLAND\",\n",
    "    \"LANGTANG NORTH\": \"LANGTANGNORTH\",\n",
    "    \"LANGTANG SOUTH\": \"LANGTANGSOUTH\",\n",
    "    \"MUBI NORTH\": \"MUBINORTH\",\n",
    "    \"MUBI SOUTH\": \"MUBISOUTH\",\n",
    "    \"NASARAWA-EGGON\": \"NASARAWAEGGON\",\n",
    "    \"NKANU EAST\": \"NKANUEAST\",\n",
    "    \"NKANU WEST\": \"NKANUWEST\",\n",
    "    \"OBIA/AKPOR\": \"OBIO/AKPOR\",\n",
    "    \"OTURKPO\": \"OTUKPO\",\n",
    "    \"OVIA NORTH EAST\": \"OVIANORTH-EAST\",\n",
    "    \"OVIA SOUTH WEST\": \"OVIASOUTH-WEST\",\n",
    "    \"OWAN EAST\": \"OWANEAST\",\n",
    "    \"OWAN WEST\": \"OWANWEST\",\n",
    "    \"PORT-HARCOURT\": \"PORTHARCOURT\",\n",
    "    \"QUA'AN PAN\": \"QUA'ANPAN\",\n",
    "    \"REMO NORTH\": \"REMO-NORTH\",\n",
    "    \"RIMIN GADO\": \"RIMINGADO\",\n",
    "    \"SABON BIRNI\": \"SABONBIRNI\",\n",
    "    \"SABON-GARI\": \"SABONGARI\",\n",
    "    \"SOKOTO NORTH\": \"SOKOTONORTH\",\n",
    "    \"SULE-TANKARKAR\": \"SULETANKARKAR\",\n",
    "    \"TALATA MAFARA\": \"TALATA-MAFARA\",\n",
    "    \"TUDUN WADA\": \"TUDUNWADA\",\n",
    "    \"UKWA EAST\": \"UKWAEAST\",\n",
    "    \"UKWA WEST\": \"UKWAWEST\",\n",
    "    \"UMUAHIA NORTH\": \"UMUAHIANORTH\",\n",
    "    \"UMUAHIA SOUTH\": \"UMUAHIASOUTH\",\n",
    "    \"UMUNNEOCHE\": \"UMUNNEOCHI\",\n",
    "    \"YAGBA EAST\": \"YAGBAEAST\",\n",
    "    \"YAGBA WEST\": \"YAGBAWEST\",\n",
    "    \"YEWA NORTH\": \"YEWANORTH\",\n",
    "    \"YEWA SOUTH\": \"YEWASOUTH\",\n",
    "    \"YOLA NORTH\": \"YOLANORTH\",\n",
    "    \"YOLA SOUTH\": \"YOLASOUTH\",\n",
    "    \"ZANGO-KATAF\": \"ZANGONKATAF\"\n",
    "}\n",
    "\n",
    "# Application sur IPC\n",
    "df_ipc['adm2_clean'] = df_ipc['adm2_name'].replace(correction_dict)\n",
    "df_ipc['adm2_clean'] = df_ipc['adm2_clean'].astype(str).str.upper().str.strip()\n",
    "\n",
    "# 3. Fusion\n",
    "print(\"Fusion en cours...\")\n",
    "df_final_dataset = pd.merge(\n",
    "    df_ipc, \n",
    "    df_clim, \n",
    "    left_on='adm2_clean', \n",
    "    right_on='NAME_2', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 4. Sauvegarde\n",
    "output_file = \"FINAL_DATASET_NIGERIA.csv\"\n",
    "df_final_dataset.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"SUCCÃˆS ! Dataset final crÃ©Ã© : {len(df_final_dataset)} lignes !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "080ef1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_22216\\2800732199.py:4: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_final = pd.read_csv(\"FINAL_DATASET_NIGERIA.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PREUVE DE L'HARMONISATION ---\n",
      "Nombre de districts (LGA) uniques dans le fichier final : 445\n",
      "(Le NigÃ©ria compte environ 774 LGA. Si tu es entre 700 et 774, c'est excellent).\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['SoilMoisture00_10cm_tavg'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m cols_a_verifier = [\u001b[33m'\u001b[39m\u001b[33madm2_name\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33madm2_clean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNAME_2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mphase35\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSoilMoisture00_10cm_tavg\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# On prend 5 lignes au hasard oÃ¹ il y a des donnÃ©es\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m sample = \u001b[43mdf_final\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_a_verifier\u001b[49m\u001b[43m]\u001b[49m.sample(\u001b[32m5\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Ã‰chantillon de 5 lignes jointes ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(sample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['SoilMoisture00_10cm_tavg'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement du fichier final\n",
    "df_final = pd.read_csv(\"FINAL_DATASET_NIGERIA.csv\")\n",
    "\n",
    "print(\"--- PREUVE DE L'HARMONISATION ---\")\n",
    "\n",
    "# 1. VÃ©rification du nombre de zones\n",
    "nb_regions = df_final['NAME_2'].nunique()\n",
    "print(f\"Nombre de districts (LGA) uniques dans le fichier final : {nb_regions}\")\n",
    "print(\"(Le NigÃ©ria compte environ 774 LGA. Si tu es entre 700 et 774, c'est excellent).\")\n",
    "\n",
    "# 2. Inspection visuelle de la 'soudure'\n",
    "# On regarde le nom original (IPC) vs le nom officiel (Climat) sur la mÃªme ligne\n",
    "cols_a_verifier = ['adm2_name', 'adm2_clean', 'NAME_2', 'phase35', 'SoilMoisture00_10cm_tavg']\n",
    "\n",
    "# On prend 5 lignes au hasard oÃ¹ il y a des donnÃ©es\n",
    "sample = df_final[cols_a_verifier].sample(5)\n",
    "\n",
    "print(\"\\n--- Ã‰chantillon de 5 lignes jointes ---\")\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e41053b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LISTE OFFICIELLE DES COLONNES ---\n",
      "ðŸ‘‰ adm0_name\n",
      "ðŸ‘‰ adm0_pcod2\n",
      "ðŸ‘‰ adm0_pcod3\n",
      "ðŸ‘‰ adm0_5_name\n",
      "ðŸ‘‰ adm0_5_pcod2\n",
      "ðŸ‘‰ adm1_name\n",
      "ðŸ‘‰ adm1_pcod2\n",
      "ðŸ‘‰ adm1_5_name\n",
      "ðŸ‘‰ adm1_5_pcod2\n",
      "ðŸ‘‰ adm2_name\n",
      "ðŸ‘‰ adm2_pcod2\n",
      "ðŸ‘‰ adm3_pcod2\n",
      "ðŸ‘‰ exercise_code\n",
      "ðŸ‘‰ exercise_label\n",
      "ðŸ‘‰ exercise_year\n",
      "ðŸ‘‰ chtype\n",
      "ðŸ‘‰ population\n",
      "ðŸ‘‰ phase_class\n",
      "ðŸ‘‰ phase1\n",
      "ðŸ‘‰ phase2\n",
      "ðŸ‘‰ phase3\n",
      "ðŸ‘‰ phase4\n",
      "ðŸ‘‰ phase5\n",
      "ðŸ‘‰ phase35\n",
      "ðŸ‘‰ adm2_clean\n",
      "ðŸ‘‰ time\n",
      "ðŸ‘‰ NAME_1\n",
      "ðŸ‘‰ NAME_2\n",
      "ðŸ‘‰ Evap_tavg\n",
      "ðŸ‘‰ LWdown_f_tavg\n",
      "ðŸ‘‰ Lwnet_tavg\n",
      "ðŸ‘‰ Psurf_f_tavg\n",
      "ðŸ‘‰ Qair_f_tavg\n",
      "ðŸ‘‰ Qg_tavg\n",
      "ðŸ‘‰ Qh_tavg\n",
      "ðŸ‘‰ Qle_tavg\n",
      "ðŸ‘‰ Qs_tavg\n",
      "ðŸ‘‰ Qsb_tavg\n",
      "ðŸ‘‰ RadT_tavg\n",
      "ðŸ‘‰ Rainf_f_tavg\n",
      "ðŸ‘‰ SWE_inst\n",
      "ðŸ‘‰ SWdown_f_tavg\n",
      "ðŸ‘‰ SnowCover_inst\n",
      "ðŸ‘‰ SnowDepth_inst\n",
      "ðŸ‘‰ Snowf_tavg\n",
      "ðŸ‘‰ Swnet_tavg\n",
      "ðŸ‘‰ Tair_f_tavg\n",
      "ðŸ‘‰ Wind_f_tavg\n",
      "ðŸ‘‰ SoilMoi00_10cm_tavg\n",
      "ðŸ‘‰ SoilMoi10_40cm_tavg\n",
      "ðŸ‘‰ SoilMoi40_100cm_tavg\n",
      "ðŸ‘‰ SoilMoi100_200cm_tavg\n",
      "ðŸ‘‰ SoilTemp00_10cm_tavg\n",
      "ðŸ‘‰ SoilTemp10_40cm_tavg\n",
      "ðŸ‘‰ SoilTemp40_100cm_tavg\n",
      "ðŸ‘‰ SoilTemp100_200cm_tavg\n",
      "\n",
      "------------------------------\n",
      "--- APERÃ‡U DU FICHIER FINAL ---\n",
      "  adm0_name adm0_pcod2 adm0_pcod3  adm0_5_name  adm0_5_pcod2 adm1_name  \\\n",
      "0   Nigeria         NG        NGA          NaN           NaN     Gombe   \n",
      "1   Nigeria         NG        NGA          NaN           NaN     Gombe   \n",
      "2   Nigeria         NG        NGA          NaN           NaN     Gombe   \n",
      "3   Nigeria         NG        NGA          NaN           NaN     Gombe   \n",
      "4   Nigeria         NG        NGA          NaN           NaN     Gombe   \n",
      "\n",
      "  adm1_pcod2    adm1_5_name adm1_5_pcod2 adm2_name  ... Tair_f_tavg  \\\n",
      "0       NG16  Gombe Central      NG01601      Akko  ...   295.44380   \n",
      "1       NG16  Gombe Central      NG01601      Akko  ...   298.26970   \n",
      "2       NG16  Gombe Central      NG01601      Akko  ...   302.62866   \n",
      "3       NG16  Gombe Central      NG01601      Akko  ...   301.19107   \n",
      "4       NG16  Gombe Central      NG01601      Akko  ...   299.87973   \n",
      "\n",
      "   Wind_f_tavg  SoilMoi00_10cm_tavg SoilMoi10_40cm_tavg  SoilMoi40_100cm_tavg  \\\n",
      "0     7.376234             0.153800            0.346961              0.352089   \n",
      "1     8.111750             0.147464            0.336445              0.341699   \n",
      "2     5.717865             0.149106            0.330567              0.335564   \n",
      "3     5.073179             0.203690            0.329308              0.333594   \n",
      "4     4.916486             0.292827            0.326689              0.329967   \n",
      "\n",
      "  SoilMoi100_200cm_tavg  SoilTemp00_10cm_tavg  SoilTemp10_40cm_tavg  \\\n",
      "0              0.368408             296.12460             296.21597   \n",
      "1              0.358832             299.19684             298.30210   \n",
      "2              0.351844             303.43622             302.03384   \n",
      "3              0.346686             302.72183             302.36606   \n",
      "4              0.342687             300.94012             301.21283   \n",
      "\n",
      "   SoilTemp40_100cm_tavg  SoilTemp100_200cm_tavg  \n",
      "0              296.43713               296.90494  \n",
      "1              297.60660               297.21780  \n",
      "2              300.51343               298.98935  \n",
      "3              301.78183               300.82278  \n",
      "4              301.40800               301.26984  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. On affiche tous les noms de colonnes disponibles\n",
    "print(\"--- LISTE OFFICIELLE DES COLONNES ---\")\n",
    "cols = df_final.columns.tolist()\n",
    "for c in cols:\n",
    "    print(f\"ðŸ‘‰ {c}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "\n",
    "# 2. On affiche les 5 premiÃ¨res lignes sans filtrer (pour voir les donnÃ©es)\n",
    "print(\"--- APERÃ‡U DU FICHIER FINAL ---\")\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1d136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_22216\\3164256472.py:5: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement de 579960 lignes et 56 colonnes.\n",
      "------------------------------\n",
      "âœ… Fichier COMPLET sauvegardÃ© : NIGERIA_FINAL_FULL.csv\n",
      "Il contient 53 variables (Climat + IPC).\n",
      "PrÃªt pour le push GitHub.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Chargement du fichier fusionnÃ©\n",
    "input_file = \"FINAL_DATASET_NIGERIA.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "print(f\"Chargement de {len(df)} lignes et {len(df.columns)} colonnes.\")\n",
    "\n",
    "# 2. Suppression des doublons techniques uniquement\n",
    "# 'adm2_clean' : servait juste de pont pour la fusion\n",
    "# 'NAME_1', 'NAME_2' : ce sont les noms GADM, redondants avec adm1_name/adm2_name\n",
    "cols_techniques_a_supprimer = ['adm2_clean', 'NAME_1', 'NAME_2']\n",
    "\n",
    "# On supprime seulement si elles existent\n",
    "df_full = df.drop(columns=[c for c in cols_techniques_a_supprimer if c in df.columns])\n",
    "\n",
    "# 3. Renommage optionnel pour plus de clartÃ© (sans supprimer de donnÃ©es)\n",
    "# On rend juste les noms techniques de la NASA plus lisibles\n",
    "mapping_climat = {\n",
    "    'time': 'Date',\n",
    "    'Rainf_f_tavg': 'Rainfall',\n",
    "    'Tair_f_tavg': 'Air_Temp',\n",
    "    'Wind_f_tavg': 'Wind_Speed',\n",
    "    'Qair_f_tavg': 'Specific_Humidity',\n",
    "    'Psurf_f_tavg': 'Surface_Pressure',\n",
    "    'SoilMoi00_10cm_tavg': 'Soil_Moisture_00_10cm',\n",
    "    'SoilMoi10_40cm_tavg': 'Soil_Moisture_10_40cm',\n",
    "    'SoilMoi40_100cm_tavg': 'Soil_Moisture_40_100cm',\n",
    "    'SoilMoi100_200cm_tavg': 'Soil_Moisture_100_200cm',\n",
    "    'SoilTemp00_10cm_tavg': 'Soil_Temp_00_10cm'\n",
    "}\n",
    "\n",
    "df_full = df_full.rename(columns=mapping_climat)\n",
    "\n",
    "# 4. Sauvegarde\n",
    "output_filename = \"NIGERIA_FINAL_FULL.csv\"\n",
    "df_full.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Fichier COMPLET sauvegardÃ© : {output_filename}\")\n",
    "print(f\"Il contient {len(df_full.columns)} variables (Climat + IPC).\")\n",
    "print(\"PrÃªt pour le push GitHub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d4852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_13604\\1748375043.py:21: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, chunksize=chunksize):\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_13604\\1748375043.py:21: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, chunksize=chunksize):\n"
     ]
    }
   ],
   "source": [
    "#transformation en parquet \n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "csv_file = \"FINAL_DATASET_NIGERIA.csv\"\n",
    "parquet_file = \"FINAL_DATASET_NIGERIA.parquet\"\n",
    "chunksize = 100_000\n",
    "\n",
    "# Ã©chantillon pour construire un schÃ©ma stable\n",
    "sample = pd.read_csv(csv_file, nrows=5000)\n",
    "\n",
    "# Convertir explicitement les colonnes \"suspectes\" en string\n",
    "for c in sample.columns:\n",
    "    if \"name\" in c.lower() or \"pcod\" in c.lower():\n",
    "        sample[c] = sample[c].astype(\"string\")\n",
    "\n",
    "schema = pa.Table.from_pandas(sample, preserve_index=False).schema\n",
    "\n",
    "writer = pq.ParquetWriter(parquet_file, schema)\n",
    "\n",
    "for chunk in pd.read_csv(csv_file, chunksize=chunksize):\n",
    "    for c in chunk.columns:\n",
    "        if \"name\" in c.lower() or \"pcod\" in c.lower():\n",
    "            chunk[c] = chunk[c].astype(\"string\")\n",
    "\n",
    "    table = pa.Table.from_pandas(chunk, preserve_index=False).cast(schema)\n",
    "    writer.write_table(table)\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178e7c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adm0_name</th>\n",
       "      <th>adm0_pcod2</th>\n",
       "      <th>adm0_pcod3</th>\n",
       "      <th>adm0_5_name</th>\n",
       "      <th>adm0_5_pcod2</th>\n",
       "      <th>adm1_name</th>\n",
       "      <th>adm1_pcod2</th>\n",
       "      <th>adm1_5_name</th>\n",
       "      <th>adm1_5_pcod2</th>\n",
       "      <th>adm2_name</th>\n",
       "      <th>...</th>\n",
       "      <th>Tair_f_tavg</th>\n",
       "      <th>Wind_f_tavg</th>\n",
       "      <th>SoilMoi00_10cm_tavg</th>\n",
       "      <th>SoilMoi10_40cm_tavg</th>\n",
       "      <th>SoilMoi40_100cm_tavg</th>\n",
       "      <th>SoilMoi100_200cm_tavg</th>\n",
       "      <th>SoilTemp00_10cm_tavg</th>\n",
       "      <th>SoilTemp10_40cm_tavg</th>\n",
       "      <th>SoilTemp40_100cm_tavg</th>\n",
       "      <th>SoilTemp100_200cm_tavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>NG</td>\n",
       "      <td>NGA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Gombe</td>\n",
       "      <td>NG16</td>\n",
       "      <td>Gombe Central</td>\n",
       "      <td>NG01601</td>\n",
       "      <td>Akko</td>\n",
       "      <td>...</td>\n",
       "      <td>295.44380</td>\n",
       "      <td>7.376234</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.346961</td>\n",
       "      <td>0.352089</td>\n",
       "      <td>0.368408</td>\n",
       "      <td>296.12460</td>\n",
       "      <td>296.21597</td>\n",
       "      <td>296.43713</td>\n",
       "      <td>296.90494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>NG</td>\n",
       "      <td>NGA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Gombe</td>\n",
       "      <td>NG16</td>\n",
       "      <td>Gombe Central</td>\n",
       "      <td>NG01601</td>\n",
       "      <td>Akko</td>\n",
       "      <td>...</td>\n",
       "      <td>298.26970</td>\n",
       "      <td>8.111750</td>\n",
       "      <td>0.147464</td>\n",
       "      <td>0.336445</td>\n",
       "      <td>0.341699</td>\n",
       "      <td>0.358832</td>\n",
       "      <td>299.19684</td>\n",
       "      <td>298.30210</td>\n",
       "      <td>297.60660</td>\n",
       "      <td>297.21780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>NG</td>\n",
       "      <td>NGA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Gombe</td>\n",
       "      <td>NG16</td>\n",
       "      <td>Gombe Central</td>\n",
       "      <td>NG01601</td>\n",
       "      <td>Akko</td>\n",
       "      <td>...</td>\n",
       "      <td>302.62866</td>\n",
       "      <td>5.717865</td>\n",
       "      <td>0.149106</td>\n",
       "      <td>0.330567</td>\n",
       "      <td>0.335564</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>303.43622</td>\n",
       "      <td>302.03384</td>\n",
       "      <td>300.51343</td>\n",
       "      <td>298.98935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>NG</td>\n",
       "      <td>NGA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Gombe</td>\n",
       "      <td>NG16</td>\n",
       "      <td>Gombe Central</td>\n",
       "      <td>NG01601</td>\n",
       "      <td>Akko</td>\n",
       "      <td>...</td>\n",
       "      <td>301.19107</td>\n",
       "      <td>5.073179</td>\n",
       "      <td>0.203690</td>\n",
       "      <td>0.329308</td>\n",
       "      <td>0.333594</td>\n",
       "      <td>0.346686</td>\n",
       "      <td>302.72183</td>\n",
       "      <td>302.36606</td>\n",
       "      <td>301.78183</td>\n",
       "      <td>300.82278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>NG</td>\n",
       "      <td>NGA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Gombe</td>\n",
       "      <td>NG16</td>\n",
       "      <td>Gombe Central</td>\n",
       "      <td>NG01601</td>\n",
       "      <td>Akko</td>\n",
       "      <td>...</td>\n",
       "      <td>299.87973</td>\n",
       "      <td>4.916486</td>\n",
       "      <td>0.292827</td>\n",
       "      <td>0.326689</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>0.342687</td>\n",
       "      <td>300.94012</td>\n",
       "      <td>301.21283</td>\n",
       "      <td>301.40800</td>\n",
       "      <td>301.26984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  adm0_name adm0_pcod2 adm0_pcod3 adm0_5_name adm0_5_pcod2 adm1_name  \\\n",
       "0   Nigeria         NG        NGA        <NA>         <NA>     Gombe   \n",
       "1   Nigeria         NG        NGA        <NA>         <NA>     Gombe   \n",
       "2   Nigeria         NG        NGA        <NA>         <NA>     Gombe   \n",
       "3   Nigeria         NG        NGA        <NA>         <NA>     Gombe   \n",
       "4   Nigeria         NG        NGA        <NA>         <NA>     Gombe   \n",
       "\n",
       "  adm1_pcod2    adm1_5_name adm1_5_pcod2 adm2_name  ... Tair_f_tavg  \\\n",
       "0       NG16  Gombe Central      NG01601      Akko  ...   295.44380   \n",
       "1       NG16  Gombe Central      NG01601      Akko  ...   298.26970   \n",
       "2       NG16  Gombe Central      NG01601      Akko  ...   302.62866   \n",
       "3       NG16  Gombe Central      NG01601      Akko  ...   301.19107   \n",
       "4       NG16  Gombe Central      NG01601      Akko  ...   299.87973   \n",
       "\n",
       "  Wind_f_tavg  SoilMoi00_10cm_tavg SoilMoi10_40cm_tavg  SoilMoi40_100cm_tavg  \\\n",
       "0    7.376234             0.153800            0.346961              0.352089   \n",
       "1    8.111750             0.147464            0.336445              0.341699   \n",
       "2    5.717865             0.149106            0.330567              0.335564   \n",
       "3    5.073179             0.203690            0.329308              0.333594   \n",
       "4    4.916486             0.292827            0.326689              0.329967   \n",
       "\n",
       "  SoilMoi100_200cm_tavg  SoilTemp00_10cm_tavg  SoilTemp10_40cm_tavg  \\\n",
       "0              0.368408             296.12460             296.21597   \n",
       "1              0.358832             299.19684             298.30210   \n",
       "2              0.351844             303.43622             302.03384   \n",
       "3              0.346686             302.72183             302.36606   \n",
       "4              0.342687             300.94012             301.21283   \n",
       "\n",
       "   SoilTemp40_100cm_tavg  SoilTemp100_200cm_tavg  \n",
       "0              296.43713               296.90494  \n",
       "1              297.60660               297.21780  \n",
       "2              300.51343               298.98935  \n",
       "3              301.78183               300.82278  \n",
       "4              301.40800               301.26984  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"FINAL_DATASET_NIGERIA.parquet\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1360e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction qui convertit les csv en parquet\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "def csv_to_parquet(\n",
    "    csv_path: str | Path,\n",
    "    parquet_path: str | Path | None = None,\n",
    "    chunksize: int = 100_000,\n",
    "    *,\n",
    "    sep: str = \",\",\n",
    "    encoding: str | None = None,\n",
    "    low_memory: bool = False,\n",
    "    text_cols_contains: tuple[str, ...] = (\"name\", \"pcod\"),\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Convertit un CSV en Parquet en lecture par chunks (adaptÃ© aux gros fichiers).\n",
    "    - Stabilise le schÃ©ma Parquet sur le 1er chunk.\n",
    "    - Force en 'string' les colonnes dont le nom contient certains mots-clÃ©s (par dÃ©faut: name, pcod),\n",
    "      pour Ã©viter les changements de dtype entre chunks.\n",
    "    \"\"\"\n",
    "    csv_path = Path(csv_path)\n",
    "    if parquet_path is None:\n",
    "        parquet_path = csv_path.with_suffix(\".parquet\")\n",
    "    parquet_path = Path(parquet_path)\n",
    "\n",
    "    writer: pq.ParquetWriter | None = None\n",
    "    schema: pa.Schema | None = None\n",
    "\n",
    "    read_kwargs = dict(\n",
    "        sep=sep,\n",
    "        chunksize=chunksize,\n",
    "        low_memory=low_memory,\n",
    "    )\n",
    "    if encoding is not None:\n",
    "        read_kwargs[\"encoding\"] = encoding\n",
    "\n",
    "    try:\n",
    "        for chunk in pd.read_csv(csv_path, **read_kwargs):\n",
    "            # Forcer les colonnes texte \"instables\" en string (ex: *_name, *_pcod*)\n",
    "            if text_cols_contains:\n",
    "                for c in chunk.columns:\n",
    "                    cl = c.lower()\n",
    "                    if any(k in cl for k in text_cols_contains):\n",
    "                        chunk[c] = chunk[c].astype(\"string\")\n",
    "\n",
    "            table = pa.Table.from_pandas(chunk, preserve_index=False)\n",
    "\n",
    "            if writer is None:\n",
    "                schema = table.schema\n",
    "                writer = pq.ParquetWriter(parquet_path, schema)\n",
    "\n",
    "            # Cast vers le schÃ©ma initial pour garantir la stabilitÃ©\n",
    "            table = table.cast(schema)\n",
    "            writer.write_table(table)\n",
    "\n",
    "    finally:\n",
    "        if writer is not None:\n",
    "            writer.close()\n",
    "\n",
    "    return parquet_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8380f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL_DATASET_NIGERIA.csv -> FINAL_DATASET_NIGERIA.parquet\n",
      "FLDAS_Nigeria_Admin2_Aggregated.csv -> FLDAS_Nigeria_Admin2_Aggregated.parquet\n",
      "FLDAS_Nigeria_pixels.csv -> FLDAS_Nigeria_pixels.parquet\n",
      "FLDAS_Nigeria_pixels_full.csv -> FLDAS_Nigeria_pixels_full.parquet\n",
      "geodata_FLDAS_Nigeria.csv -> geodata_FLDAS_Nigeria.parquet\n",
      "geodata_FLDAS_Nigeria_full.csv -> geodata_FLDAS_Nigeria_full.parquet\n",
      "NIGERIA_FINAL_FULL.csv -> NIGERIA_FINAL_FULL.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folder = Path(r\"C:\\Users\\valen\\OneDrive\\Documents\\GitHub\\Projet-de-Statapp---WFP-\\Dataset creation - NASA Nigeria\")  # mets ton dossier ici\n",
    "for csv_file in folder.glob(\"*.csv\"):\n",
    "    out = csv_to_parquet(csv_file)\n",
    "    print(csv_file.name, \"->\", out.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
